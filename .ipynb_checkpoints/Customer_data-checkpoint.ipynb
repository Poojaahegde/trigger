{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb44cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import datetime\n",
    "import boto3\n",
    "import schedule\n",
    "import time\n",
    "import import_ipynb\n",
    "import nbimporter\n",
    "from faker import Faker\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8a3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "faker = Faker()\n",
    "\n",
    "def generate_conversation_data(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        data.append({\n",
    "            'customer_id': faker.uuid4(),\n",
    "            'conversation_id': faker.uuid4(),\n",
    "            'agent_id': faker.uuid4(),\n",
    "            'call_start': faker.date_time_this_year(),\n",
    "            'call_end': faker.date_time_this_year(),\n",
    "            'call_duration_sec': random.randint(30, 600),\n",
    "            'call_status': random.choice(['Answered', 'Missed', 'Rejected', 'Hangup', 'Voicemail']),\n",
    "            'transcript': faker.sentence(),\n",
    "            'sentiment_score': random.uniform(0, 1),\n",
    "            'keywords': [faker.word() for _ in range(random.randint(1, 5))],\n",
    "            'created_at': datetime.datetime.now(),\n",
    "            'updated_at': datetime.datetime.now()\n",
    "        })\n",
    "    return data\n",
    "\n",
    "synthetic_data = generate_conversation_data(num_records=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "772b665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(data):\n",
    "    metrics = {}\n",
    "    agents = set(record['agent_id'] for record in data)\n",
    "    for agent in agents:\n",
    "        agent_data = [record['call_duration_sec'] for record in data if record['agent_id'] == agent]\n",
    "        metrics[agent] = {\n",
    "            'average_call_length': mean(agent_data),\n",
    "            '90th_percentile_call_length': np.percentile(agent_data, 90)\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "metrics = calculate_metrics(synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8be51c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_metrics_to_csv(metrics, csv_filename):\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Agent ID', 'Average Call Length', '90th Percentile Call Length'])\n",
    "        for agent, metric in metrics.items():\n",
    "            writer.writerow([agent, metric['average_call_length'], metric['90th_percentile_call_length']])\n",
    "\n",
    "csv_filename = 'metrics.csv'\n",
    "write_metrics_to_csv(metrics, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e2d355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from s3_upload.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Import the `upload_csv_to_s3` function from the notebook\n",
    "from s3_upload import upload_csv_to_s3\n",
    "\n",
    "# Specify the necessary parameters\n",
    "csv_filename = 'metrics.csv'\n",
    "bucket_name = 'conversationcustomerdata'\n",
    "\n",
    "# Call the upload_csv_to_s3 function\n",
    "upload_csv_to_s3(csv_filename, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b9bfa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing daily task...\n",
      "Synthetic data generated.\n",
      "Metrics calculated.\n",
      "Metrics written to CSV file.\n",
      "CSV file uploaded to S3.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def run_daily_task():\n",
    "    synthetic_data = generate_conversation_data(num_records=1000)\n",
    "    print(\"Synthetic data generated.\")\n",
    "    \n",
    "    metrics = calculate_metrics(synthetic_data)\n",
    "    print(\"Metrics calculated.\")\n",
    "    \n",
    "    csv_filename = 'metrics.csv'\n",
    "    write_metrics_to_csv(metrics, csv_filename)\n",
    "    print(\"Metrics written to CSV file.\")\n",
    "    \n",
    "    bucket_name = 'conversationcustomerdata'\n",
    "    upload_csv_to_s3(csv_filename, bucket_name)\n",
    "    print(\"CSV file uploaded to S3.\")\n",
    "\n",
    "# Check if it's time to execute the task\n",
    "current_time = datetime.datetime.now().strftime(\"%H:%M\")\n",
    "scheduled_time = \"16:15\"  # Set the desired scheduled time\n",
    "\n",
    "if current_time >= scheduled_time:\n",
    "    print(\"Executing daily task...\")\n",
    "    run_daily_task()\n",
    "else:\n",
    "    print(\"It's not yet time to execute the daily task.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
